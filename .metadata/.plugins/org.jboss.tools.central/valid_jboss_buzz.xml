<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0" uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Simplify client connection configurations with service contexts</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/18/simplify-client-connection-configurations-service-contexts" /><author><name>Ramakrishna Pattnaik, John Byrne</name></author><id>18f84491-1c55-4d59-b93b-acd4ebc36a4a</id><updated>2022-07-18T07:00:00Z</updated><published>2022-07-18T07:00:00Z</published><summary type="html">&lt;p&gt;The latest release of &lt;code&gt;rhoas&lt;/code&gt;, the command-line interface (CLI) for &lt;a href="https://www.redhat.com/en/technologies/cloud-computing/openshift/application-services"&gt;Red Hat OpenShift application services&lt;/a&gt;, adds a powerful and flexible feature called &lt;em&gt;service contexts&lt;/em&gt; that makes it easier than ever to connect clients to your instances of OpenShift application services. This article illustrates this new feature and shows how it can accelerate your development workflows for stream-based applications.&lt;/p&gt; &lt;h2&gt;Service contexts facilitate client connections&lt;/h2&gt; &lt;p&gt;Red Hat OpenShift application services, such as &lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/overview"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; and &lt;a href="https://developers.redhat.com/articles/2021/10/11/get-started-openshift-service-registry"&gt;Red Hat OpenShift Service Registry&lt;/a&gt;, are managed cloud services that provide a streamlined developer experience for building, deploying, and scaling real-time applications in hybrid-cloud environments.&lt;/p&gt; &lt;p&gt;The OpenShift application services CLI is a rich command-line interface for managing application services. With the new service contexts feature, you can use the CLI to define sets of service instances for specific use cases, projects, or environments, as indicated in Figure 1. After you define a context, a single command can generate the connection configuration information required by client applications.&lt;/p&gt; &lt;figure role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/or7yZYHBGpMmn7LbheiBZLYrewKSH4MATwjQk3Nk4Qy8GRgOPCiSGyyBmSSoeth0c3QVoSpZvGC9yImaApEKImBWey8brZzo-oB_7qUe7vs9fEiLNQ-ikKfRleFb5GxMoGJrTbta4hoG_jb1qg.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/or7yZYHBGpMmn7LbheiBZLYrewKSH4MATwjQk3Nk4Qy8GRgOPCiSGyyBmSSoeth0c3QVoSpZvGC9yImaApEKImBWey8brZzo-oB_7qUe7vs9fEiLNQ-ikKfRleFb5GxMoGJrTbta4hoG_jb1qg.png?itok=wlDu6yv2" width="1440" height="1057" alt="A context represents a collection of services dedicated to a particular purpose." loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: A context represents a collection of services dedicated to a particular purpose. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Thus, service contexts enable you to switch easily between defined sets of service instances and to quickly and reliably generate connection configurations for those instances. This process represents a significant improvement over time-consuming and error-prone workflows that require you to create individual configuration files for standalone service instances and applications in different languages.&lt;/p&gt; &lt;p&gt;This article shows where service contexts excel and why we're excited to introduce this feature.&lt;/p&gt; &lt;p&gt;First, we'll walk through a practical example that uses service contexts to connect a local client application to some instances in OpenShift application services. Then we'll look at how to use contexts with OpenShift-based applications and how to share contexts with other team members.&lt;/p&gt; &lt;h2&gt;Connect a Quarkus application to OpenShift application services&lt;/h2&gt; &lt;p&gt;This example uses service contexts to connect an example &lt;a href="https://developers.redhat.com/products/quarkus/overview"&gt;Quarkus&lt;/a&gt; application to some Kafka and Service Registry instances in OpenShift application services. The Quarkus application produces a stream of quotes (actually randomly generated strings of characters) and displays them on a web page.&lt;/p&gt; &lt;p&gt;First, create a brand new service context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas context create --name quotes-dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The context you just created becomes the &lt;em&gt;current&lt;/em&gt; context. You can create multiple contexts, putting different services in each one, and offering contexts to different developers to give them access to sets of services.&lt;/p&gt; &lt;p&gt;Next, create some Kafka and Service Registry instances in the current context:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka create --name example-kafka-instance --wait $ rhoas service-registry create --name example-registry-instance&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The new Kafka and Service Registry instances are automatically added to the current context. You could also add existing Kafka and Service Registry instances to the current context using the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_ceac13a8-667d-4262-984c-adfce81e59dc"&gt;context set-kafka&lt;/a&gt; and &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_90ac4ba8-8ad8-4f30-b0bb-62e2391c5f41"&gt;context set-registry&lt;/a&gt; CLI commands.&lt;/p&gt; &lt;p&gt;Now clone a sample Quarkus application to run locally:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ git clone https://github.com/redhat-developer/app-services-guides.git $ cd app-services-guides/code-examples/quarkus-service-registry-quickstart/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The sample Quarkus application has two components: A producer and a consumer. The producer generates a stream of quote messages to a Kafka topic. The consumer component consumes these messages and displays their strings on a web page.&lt;/p&gt; &lt;p&gt;The Quarkus application requires a Kafka topic called &lt;code&gt;quotes&lt;/code&gt; in your Kafka instance. Create the topic as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka topic create --name quotes&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You already created a context for your Kafka and Service Registry instances, so you're ready to generate the configuration information required to connect the Quarkus application to these instances through a &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_604e7a08-2776-4bb4-b2ee-73c09b969d28"&gt;generate-config&lt;/a&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas generate-config --type env --output-file ./producer/.env&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;All &lt;code&gt;rhoas&lt;/code&gt; commands are executed against all the service instances in the current context, so you didn't need to explicitly specify any instances in the previous command. This broad reach is an important characteristic of service contexts. The feature gives you the flexibility to quickly and seamlessly switch between large sets of service instances and run CLI commands against them.&lt;/p&gt; &lt;p&gt;The Quarkus application requires the connection configuration information for your context to be available to both the producer and the consumer. You previously generated the configuration in the producer directory, so you can simply copy the same &lt;code&gt;.env&lt;/code&gt; file to the consumer directory:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cp ./producer/.env ./consumer/.env &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;For the context that you defined, the contents of the &lt;code&gt;.env&lt;/code&gt; file should look like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="java language-markdown"&gt;## Generated by rhoas cli ## Kafka Configuration KAFKA_HOST=test-insta-ca---q---mrrjobj---a.bf2.kafka.rhcloud.com:443 ## Service Registry Configuration SERVICE_REGISTRY_URL=https://bu98.serviceregistry.rhcloud.com/t/cc8a243a-feed-4a4c-9394-5a35ce83cca5 SERVICE_REGISTRY_CORE_PATH=/apis/registry/v2 SERVICE_REGISTRY_COMPAT_PATH=/apis/ccompat/v6 ## Authentication Configuration RHOAS_CLIENT_ID=srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd RHOAS_CLIENT_SECRET=001a40b1-9a63-4c70-beda-3447b64a7783 RHOAS_OAUTH_TOKEN_URL=https://identity.api.openshift.com/auth/realms/rhoas/protocol/openid-connect/token&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;generate-config&lt;/code&gt; command created a service account (under the environment variable name &lt;code&gt;RHOAS_CLIENT_ID&lt;/code&gt;) to authenticate client applications with the Kafka and Service Registry instances in your context. To enable the service account to work with these instances, you need to grant the service account access to the instances:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas kafka acl grant-access --producer --consumer --service-account srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd --topic quotes --group all $ rhoas service-registry role add --role manager --service-account srvc-acct-45038cc5-0eb1-496f-a678-24ca7ed0a7bd &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;You previously made the &lt;code&gt;.env&lt;/code&gt; file available to both the producer and consumer components of the Quarkus application. Now use &lt;a href="https://maven.apache.org/"&gt;Apache Maven&lt;/a&gt; to run the producer component:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cd producer $ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;producer&lt;/code&gt; component starts to generate quote messages to the dedicated &lt;code&gt;quotes&lt;/code&gt; topic in the Kafka instance.&lt;/p&gt; &lt;p&gt;The Quarkus application also created a schema artifact with an ID of &lt;code&gt;quotes-value&lt;/code&gt; in the Service Registry instance. The producer uses the schema artifact to validate that each message representing a quote conforms to a defined structure. To view the contents of the schema artifact created by the Quarkus application, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas service-registry artifact get --artifact-id quotes-value&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The output is:&lt;/p&gt; &lt;pre&gt; &lt;code class="javascript language-markdown"&gt;{ "type": "record", "name": "Quote", "namespace": "org.acme.kafka.quarkus", "fields": [ { "name": "id", "type": { "type": "string", "avro.java.string": "String" } }, { "name": "price", "type": "int" } ] }&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, with the producer still running, use Apache Maven to run the consumer component:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ cd consumer $ mvn quarkus:dev&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The consumer component consumes the stream of quotes and displays them on your local web page at &lt;code&gt;http://localhost:8080/quotes.html&lt;/code&gt;. The consumer component also uses the &lt;code&gt;quotes-value&lt;/code&gt; schema artifact to validate that messages conform to the structure defined in the schema.&lt;/p&gt; &lt;p&gt;Figure 2 shows an example of the output displayed on the web page.&lt;/p&gt; &lt;figure role="group"&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;This example has shown that, after you defined a context, connecting your client application to OpenShift application services was as easy as generating a single file for connection information and copying this file to the application.&lt;/p&gt; &lt;p&gt;In the final sections of this blog post, we'll look briefly at two other use cases: Using service contexts to connect applications in &lt;a href="https://developers.redhat.com/products/openshift"&gt;Red Hat OpenShift&lt;/a&gt;, and sharing service contexts with other team members.&lt;/p&gt; &lt;h2&gt;Using service contexts to connect OpenShift-based applications&lt;/h2&gt; &lt;p&gt;In the previous example, you generated a connection configuration as a set of environment variables, which is convenient for a client application running locally. But what if you're running a container-based application on OpenShift? Well, service contexts make that easy, too. In this situation, you can directly generate the connection configuration information as an OpenShift secret file:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas generate-config --type secret --output-file ./rhoas-services-secret.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you've generated a secret, you can store it securely using methods such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;A secret-management solution such as &lt;a href="https://www.vaultproject.io/"&gt;Hashicorp Vault&lt;/a&gt;&lt;/li&gt; &lt;li&gt;The &lt;a href="https://github.com/jkroepke/helm-secrets"&gt;helm-secrets&lt;/a&gt; plug-in&lt;/li&gt; &lt;li&gt;Encrypting and pushing the secret to a GitHub repository&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;You can apply the secret to an OpenShift project using a command like the following:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ oc apply -f ./rhoas-services-secret.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you've applied the secret to your OpenShift project, you can refer to the secret from various resources, including OpenShift application templates, &lt;a href="https://docs.openshift.com/container-platform/4.7/openshift_images/using_images/using-s21-images.html"&gt;Source-to-Image&lt;/a&gt; (S2I) builds, &lt;a href="https://helm.sh"&gt;Helm charts&lt;/a&gt;, and service binding configurations.&lt;/p&gt; &lt;h2&gt;Sharing service contexts&lt;/h2&gt; &lt;p&gt;To share a context with other team members, you just need to share the context's configuration file. For example, you can push the file to a shared GitHub repository as described in this section.&lt;/p&gt; &lt;p&gt;Don't confuse the context's configuration file with the &lt;code&gt;.env&lt;/code&gt; file of environment variables that you generated for connection information earlier in the article. Instead, the context file lists the service instances that are in the context. The file contains JSON and is stored locally on your computer. To get the path to the context file, run the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ rhoas context status&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When you have the path to the file, you can copy it to a location such as a local Git repository. An example for Linux follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-markdown"&gt;$ cp &lt;path-to-context-file&gt; ./profiles.json&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;To share the service context with other developers, commit and push the file to a shared working area such as the team's Git repository. It's safe to push context files even to public repositories because the files contain only identifiers for the service instances.&lt;/p&gt; &lt;p&gt;Now, suppose another team member wants to use the shared context. When that team member has the context file (they fetched it from the shared repository, for example), they must define an environment variable called &lt;code&gt;RHOAS_CONTEXT&lt;/code&gt; that points to the context file. An example for Linux follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-html"&gt;$ export RHOAS_CONTEXT=./profiles.json&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Service contexts: Quick, safe, and scalable&lt;/h2&gt; &lt;p&gt;This article has shown how the new service contexts feature of the CLI greatly simplifies the job of connecting client applications to sets of service instances in Red Hat OpenShift application services. This powerful and flexible feature automates the work that you previously spent on manual, error-prone configuration tasks and enables your team to focus on what it does best: Developing great stream-based applications.&lt;/p&gt; &lt;p&gt;To learn how to get started with the OpenShift application services CLI and start benefiting from the service contexts feature, see our detailed documentation:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/bb30ee92-9e0a-4fd6-a67f-aed8910d7da3"&gt;Installing and configuring the rhoas CLI&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/88e1487a-2a14-4b35-85b9-a7a2d67a37f3"&gt;Getting started with the rhoas CLI for Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_streams_for_apache_kafka/1/guide/2f4bf7cf-5de2-4254-8274-6bf71673f407"&gt;Managing account access in Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_service_registry/1/guide/7717db0b-9fad-4fff-91b7-b311b63290a4"&gt;Managing account access in Red Hat OpenShift Service Registry&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_application_services/1/guide/8bd088a6-b7b7-4e5d-832a-b0f0494f9070#_b7f033ec-6f0c-4b3c-89b0-cb1801de19f9"&gt;The CLI command reference&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/18/simplify-client-connection-configurations-service-contexts" title="Simplify client connection configurations with service contexts"&gt;Simplify client connection configurations with service contexts&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Ramakrishna Pattnaik, John Byrne</dc:creator><dc:date>2022-07-18T07:00:00Z</dc:date></entry><entry><title>New HTTP clients, a Java generator, and more in Fabric8 6.0.0</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600" /><author><name>Steven Hawkins</name></author><id>e55d475c-c178-4abc-8467-d9aeb7a0866f</id><updated>2022-07-15T07:00:00Z</updated><published>2022-07-15T07:00:00Z</published><summary type="html">&lt;p&gt;The &lt;a href="https://github.com/fabric8io/kubernetes-client"&gt;Fabric8&lt;/a&gt; Kubernetes client has been simplifying &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; developers' use of &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; for several years. The 6.0.0 release represents a major body of work spanning about five months of effort in both the core of the project and in related utilities.&lt;/p&gt; &lt;p&gt;This article takes a look at new features and other important changes in the Fabric8 Kubernetes client, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;New HTTP clients&lt;/li&gt; &lt;li&gt;Java generator&lt;/li&gt; &lt;li&gt;Resource API&lt;/li&gt; &lt;li&gt;API refinements&lt;/li&gt; &lt;li&gt;Kubernetes testing improvements&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;How to get the new Fabric8 Java client&lt;/h1&gt; &lt;p&gt;You can find the most current Fabric8 Java client release on &lt;a href="https://search.maven.org/artifact/io.fabric8/kubernetes-client"&gt;Maven Central&lt;/a&gt;. To start using the new client, add it as a dependency in your Maven &lt;code&gt;pom.xml&lt;/code&gt; or Gradle build file. For Kubernetes, the dependency is:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&lt;dependency&gt; &lt;groupId&gt;io.fabric8&lt;/groupId&gt; &lt;artifactId&gt;kubernetes-client&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Or for &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;&lt;dependency&gt; &lt;groupId&gt;io.fabric8&lt;/groupId&gt; &lt;artifactId&gt;openshift-client&lt;/artifactId&gt; &lt;version&gt;6.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The sections below on the new HTTP clients API refinements will help you understand the new choices you have in your Fabric8 client dependencies.&lt;/p&gt; &lt;p&gt;And for your future Fabric8 Kubernetes client needs, please use the snapshot releases being published to &lt;a href="https://github.com/fabric8io/kubernetes-client/discussions/4208#discussioncomment-2957095"&gt;Maven Central&lt;/a&gt;.&lt;/p&gt; &lt;h1&gt;New features&lt;/h1&gt; &lt;p&gt;The feature work of the Fabric8 client has been driven by a diverse set of needs with an eye towards compatibility and continuity for existing users. So while the &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/CHANGELOG.md"&gt;changelog&lt;/a&gt; and &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/MIGRATION-v6.md"&gt;migration guide&lt;/a&gt; may be lengthy, we expect that your upgrade process will be mostly seamless.&lt;/p&gt; &lt;h2&gt;New HTTP clients&lt;/h2&gt; &lt;p&gt;With some refinements to the HTTP client API introduced in 5.x, we were able to create a &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3855"&gt;JDK&lt;/a&gt; and an &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/4180"&gt;Eclipse Jetty&lt;/a&gt; client implementation. A &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/2764"&gt;Vert.x client&lt;/a&gt; is still in the works.&lt;/p&gt; &lt;p&gt;This means you can choose the client that is best suited to your needs—which could be one that is already being used in your project. You won't be locked into additional &lt;code&gt;OkHttp&lt;/code&gt; dependencies unless you want to be.&lt;/p&gt; &lt;p&gt;Since the abstraction layer and alternative client implementations are new, please let us know if you encounter any issues with them. You should also check the repo for known issues with the respective implementation—the &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/httpclient-jdk"&gt;JDK readme&lt;/a&gt;, for example.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/FAQ.md"&gt;FAQ&lt;/a&gt; covers how to configure your project for a given HTTP client, along with several other topics. In short, you should exclude the &lt;code&gt;kubernetes-httpclient-okhttp&lt;/code&gt; dependency and add a runtime dependency to the desired HTTP client: &lt;code&gt;kubernetes-httpclient-jetty&lt;/code&gt; or &lt;code&gt;kubernetes-httpclient-jdk&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;If you need to customize the configuration of the client, you should add a compile time reference to the respective HTTP client—&lt;code&gt;kubernetes-httpclient-xxx&lt;/code&gt;—and extend its &lt;code&gt;HttpClient.Factory&lt;/code&gt;: &lt;code&gt;JettyHttpClientFactory&lt;/code&gt;, &lt;code&gt;JdkHttpClientFactory&lt;/code&gt;, and &lt;code&gt;OkHttpClientFactory&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Java generator&lt;/h2&gt; &lt;p&gt;Kubernetes is still a world dominated by &lt;a href="https://developers.redhat.com/topics/go"&gt;Go&lt;/a&gt; tools and operators. When using the &lt;code&gt;kubernetes-client&lt;/code&gt;, you often have to deal with externally defined (and generated) Custom Resource Definitions (CRDs). So far, the &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/extensions"&gt;extensions&lt;/a&gt; available for Fabric8 have partially closed the gap by offering typed Java representations for some common use cases. In the 6.x release, we are introducing a full blown Java generator capable of automatically extracting fully typed Java representations from arbitrary YAML/JSON CRDs. You can check some examples of the generated code &lt;a href="https://github.com/fabric8io/kubernetes-client/tree/6.0/java-generator/core/src/test/resources/io/fabric8/java/generator/approvals"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The tool can generate Java classes annotated with &lt;code&gt;lombok&lt;/code&gt; and &lt;code&gt;sundrio&lt;/code&gt; annotations in order to provide a seamless &lt;a href="https://github.com/fabric8io/kubernetes-client/blob/b90ee77091e50826f1c21f3c518483a5299f77b9/java-generator/it/src/it/extensions/src/test/java/io/fabric8/it/extensions/camelk/JavaGeneratedCamelK.java#L32"&gt;API and user experience&lt;/a&gt; when using those.&lt;/p&gt; &lt;p&gt;Whether you want to &lt;a href="https://andreaperuffo.com/posts/java-shell-4-kube/"&gt;easily and quickly&lt;/a&gt; interact with Java code with an external CRD, or you want to go down the path of full contract first development in your Operator, the Java generator is the instrument you are looking for.&lt;/p&gt; &lt;p&gt;Eager to start? You can find detailed instructions on how to use it in the &lt;a href="https://github.com/fabric8io/kubernetes-client/blob/6.0/doc/java-generation-from-CRD.md"&gt;official documentation&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Resource API&lt;/h2&gt; &lt;p&gt;Most operations are performed on a resource. The Fabric8 5.x APIs could make dealing with existing &lt;code&gt;KubernetesResource&lt;/code&gt; objects a little cumbersome when it came to obtaining the resource. It was quite common to do something like this:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;// obtain an existing configMap somehow ConfigMap configMap = ... ... Resource&lt;ConfigMap&gt; resource = client.configMaps().inNamespace(configMap.getMetadata().getNamespace()).withName(configMap.getMetadata().getName()); resource.delete(); // or some other operation &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In 6.0, several issues have been addressed, including &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3407"&gt;#3407&lt;/a&gt; and &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3973"&gt;#3973&lt;/a&gt;, that make it possible to obtain the Resource directly:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;Resource&lt;ConfigMap&gt; resource = client.resource(configMap); // or used fluently client.resource(configMap).delete(); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;There are other places to directly get resources. For instance, all of the following return a Stream&lt;Resource&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.configMaps().resources(); client.configMaps().withLabel("x").resources(); client.resourceList(...).resources(); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Using any of these, you can implement composite operations easily with lambdas:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.secrets().resources().forEach(Resource::delete); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Related to these changes are the cleanup and deprecation of many common operations. For example, imagine a scenario where you used both &lt;code&gt;withName()&lt;/code&gt; and a resource to perform an operation:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;client.configMaps().withName("x").replace(configMap); &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This was potentially confusing in that there was an extra check to make sure that the name specified in &lt;code&gt;withName()&lt;/code&gt; matched the name of the &lt;code&gt;KubernetesResource&lt;/code&gt; passed into &lt;code&gt;replace()&lt;/code&gt;. With 6.0, you should instead perform the operations on the resource:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;// if you need a specific resource type client.configMaps().resource(configMap).replace(); // or if it can be a general Resource client.resource(configMap).replace(); &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;API refinements&lt;/h2&gt; &lt;p&gt;The 6.0 update has gone went beyond simply adding a few new things into the domain-specific language (DSL). The DSL has now been split from the implementation and has been cleaned out of anything that seemed unnecessary.&lt;/p&gt; &lt;p&gt;The 5.x client and prior versions had the primary API and implementation as a single &lt;code&gt;kubernetes-client&lt;/code&gt; module/jar. While convenient, it did not offer a clear separation of the API from internal classes, and exposed the consuming applications compile time classpath to additional dependencies (such as &lt;code&gt;OkHttp&lt;/code&gt;). A refactoring was undertaken to split the client into a separate API and implementation module. You may still continue to use just a reference to the &lt;code&gt;kubernetes-client&lt;/code&gt; if you wish, but you now also have the option of having a compile dependency on &lt;code&gt;kubernetes-client-api&lt;/code&gt; with a runtime dependency on &lt;code&gt;kubernetes-client&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This split also required us to make direct use of the default clients; &lt;code&gt;DefaultKubernetesClient&lt;/code&gt; and &lt;code&gt;DefaultOpenShiftClient&lt;/code&gt; have been deprecated. You should transition to using the &lt;code&gt;KubernetesClientBuilder&lt;/code&gt; instead, which you will be required to use if you have just the API module as a compile time dependency.&lt;/p&gt; &lt;p&gt;This refactoring allowed us to clean up some of the details of how the client extensions are implemented. They now only have a compile dependency on the &lt;code&gt;kubernetes-client-api&lt;/code&gt;, so you may notice a few changes if you use or further extend an extension such as &lt;a href="https://developers.redhat.com/topics/camel-k"&gt;Camel K&lt;/a&gt;, Istio, cert-manager, etc.&lt;/p&gt; &lt;p&gt;Finally, we took this opportunity to remove or collapse a lot of the interfaces that were used to make up the DSL. Most users, who are using fluent style calls, won't notice these changes as the operations are still there. However, if you created an intermediate variable at some point in the method chain, that particular class may no longer exist; for example, &lt;code&gt;EditReplacePatchDeleteble&lt;/code&gt; is no more. In that case, you'll have to update the type or use &lt;code&gt;var&lt;/code&gt; instead.&lt;/p&gt; &lt;h2&gt;Kubernetes testing improvements&lt;/h2&gt; &lt;p&gt;The integration testing utilities used by the Fabric8 project were refined and exposed for general use as a JUnit 5 extension in a new &lt;code&gt;kubernetes-junit-jupiter artifact&lt;/code&gt;. The new module offers a highly declarative set of annotations that you can use to simplify your project's test setup and execution against an actual Kuberentes cluster.&lt;/p&gt; &lt;p&gt;As described in issued &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/4054"&gt;#4054&lt;/a&gt;, this module allows you to configure your tests like so:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;@KubernetesTest @LoadKubernetesManifests("/test-data.yml") @RequireK8sSupport(io.fabric8.knative.serving.v1.Service.class) // Optionally require support for a resource (test env should be reliable) @RequireK8sVersionAtLeast(majorVersion = 1, minorVersion = 16) // Optionally require a specific K8s version class MyTest { KubernetesClient client; // … } &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The extension takes care of creating a temporary namespace and injecting a &lt;code&gt;KubernetesClient&lt;/code&gt; instance preconfigured to use that namespace. In addition, the new extension provides an annotation to load and delete Kubernetes manifests before and after the test suite execution, along with two annotations to restrict the test execution to specific cluster versions, or support for specific Kubernetes resources.&lt;/p&gt; &lt;p&gt;Unit testing using the Kubernetes Mock server was also improved:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;You no longer need extension-specific modules such as &lt;code&gt;tekton-tests&lt;/code&gt;. Instead, you may directly reference the client type you need as a member variable. The appropriate instance will be initialized:&lt;/li&gt; &lt;/ul&gt; &lt;pre&gt;&lt;code&gt;@EnableKubernetesMockClient Class MyTest { TektonClient client; // … } &lt;/code&gt;&lt;/pre&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3966"&gt;#3966&lt;/a&gt;:&lt;/strong&gt; The &lt;code&gt;KubernetesMockServer&lt;/code&gt; has new methods— &lt;code&gt;reset()&lt;/code&gt; and &lt;code&gt;unsupported()&lt;/code&gt;— to reset its state and control what APIs are unsupported. The &lt;code&gt;reset()&lt;/code&gt; method is especially useful in crud mode to quickly clean out the mock server resource state in between tests.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3758"&gt;#3758&lt;/a&gt;:&lt;/strong&gt; &lt;code&gt;VersionInfo&lt;/code&gt; in &lt;code&gt;KubernetesMockServer&lt;/code&gt; can be overridden.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Other improvements&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3334"&gt;#3334&lt;/a&gt;:&lt;/strong&gt; Added basic support for server-side apply: &lt;code&gt;patch(PatchContext.of(PatchType.SERVER_SIDE_APPLY), service)&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3625"&gt;#3625&lt;/a&gt;:&lt;/strong&gt; Added default maps in generated models, mostly to prevent the need for null checks on things like annotations and labels.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Informer improvements:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3968"&gt;#3968&lt;/a&gt;:&lt;/strong&gt; &lt;code&gt;SharedIndexInformer.initialState&lt;/code&gt; can be used to set the store state before the informer starts.&lt;/li&gt; &lt;li&gt;&lt;code&gt;SharedIndexInformer&lt;/code&gt; allows for the addition and removal of indexes even after starting, and you can remove the default namespace index if you wish.&lt;/li&gt; &lt;li&gt;&lt;code&gt;Store.getKey()&lt;/code&gt; can be used rather than directly referencing static cache functions.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Issues &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3472"&gt;#3472&lt;/a&gt; and &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3587"&gt;#3587&lt;/a&gt;:&lt;/strong&gt; Customization has been opened up for the &lt;code&gt;Informer&lt;/code&gt; store/cache key function and the way in which state is stored. See &lt;code&gt;BasicItemStore&lt;/code&gt;, &lt;code&gt;ReducedStateItemStore&lt;/code&gt;, and the &lt;code&gt;SharedIndexInformer.itemStore()&lt;/code&gt; function.&lt;/li&gt; &lt;/ul&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;strong&gt;Issue &lt;a href="https://github.com/fabric8io/kubernetes-client/issues/3922"&gt;#3922&lt;/a&gt;:&lt;/strong&gt; Added &lt;code&gt;Client.supports()&lt;/code&gt; and &lt;code&gt;Client.hasApiGroup()&lt;/code&gt; methods for API server metadata introspection.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Deprecations and other important changes&lt;/h1&gt; &lt;p&gt;Since this is a major release there was quite a bit of legacy removed or deprecated, and there are various breaking changes. This section will cover some of the highlights, but please see the &lt;a href="https://raw.githubusercontent.com/fabric8io/kubernetes-client/6.0/doc/MIGRATION-v6.md"&gt;migration guide&lt;/a&gt; for a full list.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;To match the behavior of &lt;code&gt;kubectl&lt;/code&gt;, the client will now consider any call to &lt;code&gt;inNamespace&lt;/code&gt; as the namespace to use regardless of what is on a passed in item. Only if the client is left at the default namespace or a call has been made to &lt;code&gt;inAnyNamespace&lt;/code&gt; will the item namespace be used. This applies to all calls to &lt;code&gt;inNamespace&lt;/code&gt; at the client, operation, or resource level, and for all operations (load, create, delete, withItem, etc.).&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The backwards compatibility interceptor is now &lt;strong&gt;disabled&lt;/strong&gt; by default.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The &lt;code&gt;apiVersion&lt;/code&gt; on a resource being deserialized is now required.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;Deleting a collection is now implemented using a single delete call, rather than for each item. When the collection is namespaced and &lt;code&gt;inAnyNamespace&lt;/code&gt; is used, a call will be made to first determine the affected namespaces, and then a collection delete issued against each namespace. The result of the delete calls will be a list of &lt;code&gt;StatusDetails&lt;/code&gt; rather than a &lt;code&gt;boolean&lt;/code&gt; value. A best effort is made to process the response from the server to populate the items that are deleted. This information is generally useful if you wish to implement some kind of blocking delete behavior—that is, if you want to ensure the returned resources (based upon a matching UID) have been deleted.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;delete(List&lt;T&gt;)&lt;/code&gt; and &lt;code&gt;delete(T[])&lt;/code&gt; returning &lt;code&gt;boolean&lt;/code&gt; have been deprecated. They will always return &lt;code&gt;TRUE&lt;/code&gt;, and 404s on individual items will simply be ignored.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;Client.isAdaptable()&lt;/code&gt; and &lt;code&gt;Client.adapt()&lt;/code&gt; will check first if the existing client is an instance of the desired type. &lt;code&gt;Client.adapt()&lt;/code&gt; will no longer perform the &lt;code&gt;isAdaptable()&lt;/code&gt; check—that is, you may freely adapt from one client to another as long as the extension exists. If you need to make a specific check of support, please use the &lt;code&gt;Client.supports()&lt;/code&gt; method.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;Evictable.evict()&lt;/code&gt; will throw an exception rather than returning &lt;code&gt;FALSE&lt;/code&gt; if the pod is not found. This ensures that &lt;code&gt;FALSE&lt;/code&gt; strictly means that the eviction failed.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;The usage of piped streams is no longer supported—they make assumptions about reading and writing threads, which the client no longer honors. They should not be passed into the methods accepting &lt;code&gt;InputStreams&lt;/code&gt; and &lt;code&gt;OutputStreams&lt;/code&gt;.&lt;br /&gt; &lt;code&gt;ContainerResource.writingInput(PipedOutputStream in)&lt;/code&gt; and &lt;code&gt;readingXXX(PipedInputStream out)&lt;/code&gt; have been removed—use the redirecting methods instead.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;code&gt;TtyExecErrorChannelable&lt;/code&gt; methods have been deprecated in favor of &lt;code&gt;ExecWatch.exitCode()&lt;/code&gt; and &lt;code&gt;ExecListener.onExit()&lt;/code&gt;.&lt;br /&gt; &lt;code&gt;ContainerResource.readingInput(InputStream in)&lt;/code&gt; has been deprecated—use &lt;code&gt;redirectingInput()&lt;/code&gt; instead.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h1&gt;Learn more about Fabric8&lt;/h1&gt; &lt;p&gt;Fabric8's development team consists mostly of Java developers, so a Java developer's perspective heavily influences this client. If you want to work with us, please don't hesitate to join our community. There are a few ways to get involved with the development of the &lt;a href="https://github.com/fabric8io/kubernetes-client"&gt;Fabric8 Kubernetes Java client&lt;/a&gt;:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create &lt;a href="https://github.com/fabric8io/kubernetes-client/issues"&gt;GitHub issues&lt;/a&gt; to let us know when features don't work as expected.&lt;/li&gt; &lt;li&gt;Participate in the &lt;a href="https://github.com/fabric8io/kubernetes-client/discussions"&gt;Fabric8 Kubernetes Client GitHub discussions&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Send &lt;a href="https://github.com/fabric8io/kubernetes-client/pulls"&gt;pull requests&lt;/a&gt; for bug fixes and enhancements.&lt;/li&gt; &lt;li&gt;Chat with us on the Fabric8 Kubernetes Java client &lt;a href="https://gitter.im/fabric8io/kubernetes-client"&gt;Gitter channel&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Ask Fabric8 related questions on &lt;a href="https://stackoverflow.com/questions/tagged/fabric8"&gt;StackOverflow&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Follow us on &lt;a href="https://twitter.com/fabric8io/"&gt;Twitter&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/15/new-http-clients-java-generator-and-more-fabric8-600" title="New HTTP clients, a Java generator, and more in Fabric8 6.0.0"&gt;New HTTP clients, a Java generator, and more in Fabric8 6.0.0&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Steven Hawkins</dc:creator><dc:date>2022-07-15T07:00:00Z</dc:date></entry><entry><title type="html">How to select the "right" service with Stork?</title><link rel="alternate" href="https://quarkus.io/blog/stork-load-balancing/" /><author><name>Clement Escoffier</name></author><id>https://quarkus.io/blog/stork-load-balancing/</id><updated>2022-07-15T00:00:00Z</updated><content type="html">The essence of distributed systems resides in the interaction between services. In modern architectures, you often have multiple instances of your service to share the load or improve the resilience by redundancy. But, when you have all these instances, how do you select the best one? That’s where Stork helps....</content><dc:creator>Clement Escoffier</dc:creator></entry><entry><title type="html">Getting started with JSF 4.0 on WildFly 27</title><link rel="alternate" href="http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/</id><updated>2022-07-14T16:40:00Z</updated><content type="html">This article contains a preview of Jakarta Faces 4.0 which is an MVC framework for building user interface with Jakarta EE 10. To get started with Jakarta EE 10, you need to download the latest release of WildFly 27 which you can use to preview Jakarta EE 10 features. At the time of writing, the ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title type="html">Infinispan 14.0.0.Dev04</title><link rel="alternate" href="https://infinispan.org/blog/2022/07/14/infinispan-14" /><author><name>William Burns</name></author><id>https://infinispan.org/blog/2022/07/14/infinispan-14</id><updated>2022-07-14T12:00:00Z</updated><content type="html">Dear Infinispan community, Infinispan 14 development release 04 is here! We are nearing the final release of Infinispan 14 Final, so we want to share a preview of what’s coming. HOTROD 4.0 PROTOCOL With the addition of the new API that was released in the previous Dev03 build of Infinispan we have had to update the HotRod protocol to satisfy the requirements of that API. The new protocol changes many of the operations to return additional information to include entry metadata as well as adding new header information to support the OpenTelemetry feature described below. OPENTELEMETRY Support OpenTelemetry tracing, for tracing cache operations executed by the Infinispan server, correlated with client requests (using both Hot Rod and REST APIs). Look out for a separate blog post describing this is in more detail later! REST ENDPOINT New distribution endpoint to provide exposing the data distribution information about the node and cluster. Includes node name, number of entries and total number of entries in the cluster RESP SERVER CONNECTOR The RESP connector is now exposed by default on the single port with the other protocols. If not explicitly configured a Replicated cache is used for its cache. IOURING SERVER COMPATIBILITY Our server can now utilize IOUring for its network socket connections. This requires a compatible Linux kernel to work properly. This can be enabled by setting the JVM property infinispan.server.channel.iouring to true. COMMAND LINE INTERFACE It is now possible to access the entry value information for data in the cache. Previously only the key information was available. MULTIMAP DUPLICATES The Multimap API has been enhanced to now support duplicate values for a given key. This is an optional configuration as you can still allow only distinct values for a given key. For example, your data may be A = [1,2,3,3,5] when duplicates are allowed. SIZE COMMAND OPTIMIZATIONS Size command has received some optimizations to increase performance under certain circumstances. This includes cases of shared stores and not having expiration for data. DOCUMENTATION As always, the Infinispan team hope you find the documentation useful and complete. We’d love to hear from you and really value feedback from our community. If you think something is missing from the docs or spot a correction, please get in touch and we’ll get on it straight away. RELEASE NOTES You can look at the to see what has changed. Get them from our .</content><dc:creator>William Burns</dc:creator></entry><entry><title>Kafka Monthly Digest: June 2022</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/14/kafka-monthly-digest-june-2022" /><author><name>Mickael Maison</name></author><id>83d0e7ab-3fe2-49d8-af94-1f19466b1b5e</id><updated>2022-07-14T07:00:00Z</updated><published>2022-07-14T07:00:00Z</published><summary type="html">&lt;p&gt;This 53rd edition of the Kafka Monthly Digest covers what happened in the &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt; community in June 2022.&lt;/p&gt; &lt;p&gt;For last month’s digest, see &lt;a href="https://developers.redhat.com/articles/2022/06/06/kafka-monthly-digest-may-2022"&gt;Kafka Monthly Digest: May 2022&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Releases&lt;/h2&gt; &lt;p&gt;There is currently one release in progress: 3.3.0.&lt;/p&gt; &lt;h3&gt;3.3.0&lt;/h3&gt; &lt;p&gt;The release process for 3.3.0 continued. KIP freeze happened on June 15, and feature freeze happened on July 6. You can find the &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Release+Plan+3.3.0"&gt;release plan&lt;/a&gt; in the wiki.&lt;/p&gt; &lt;h2&gt;Kafka Improvement Proposals&lt;/h2&gt; &lt;p&gt;Last month, the community submitted 4 &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/Kafka+Improvement+Proposals"&gt;KIPs&lt;/a&gt; (KIP-847 to KIP-850). I'll highlight a few of them:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-847%3A+Add+ProducerIdCount+metrics"&gt;&lt;strong&gt;KIP-847: Add ProducerCount metrics&lt;/strong&gt;&lt;/a&gt;: This KIP proposes adding new metrics to track how many idempotent and transactional producers are connected to each broker. For each idempotent or transactional producer connected, brokers keep in memory some metadata about it. The goal is to improve observability and help diagnose whether there may be too many producers connected.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-848%3A+The+Next+Generation+of+the+Consumer+Rebalance+Protocol"&gt;&lt;strong&gt;KIP-848: The Next Generation of the Consumer Rebalance Protocol&lt;/strong&gt;&lt;/a&gt;: The Kafka group membership protocol allows distributing resources amongst client instances. It is used by consumers when they are in groups, but also by Connect and Streams. While this protocol is very flexible, over the years a few pain points have been identified. This KIP proposes significantly updating this protocol to make rebalances lightweight and simplify troubleshooting by moving most of the logic to the server side.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-849%3A+Expose+logdirs+total+and+usable+space+via+kafka-log-dirs.sh"&gt;&lt;strong&gt;KIP-849: Expose logdirs total and usable space via kafka-log-dirs.sh&lt;/strong&gt;&lt;/a&gt;: In Kafka 3.2, &lt;a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-827%3A+Expose+logdirs+total+and+usable+space+via+Kafka+API"&gt;KIP-827&lt;/a&gt; exposed the size of usable and total space of log directories via the Admin API. This KIP aims at updating &lt;code&gt;kafka-log-dirs.sh&lt;/code&gt; to include these values in its output so administrators can easily access them.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Community releases&lt;/h2&gt; &lt;ul&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/edenhill/librdkafka/releases/tag/v1.9.0"&gt;Librdkafka 1.9.0&lt;/a&gt;. Librdkafka is a Kafka client in &lt;a href="https://developers.redhat.com/topics/c"&gt;C/C++&lt;/a&gt;. This new release adds support for OAuthbearer OIDC and admin APIs for managing ACLs. As always, it also brings in many improvements and bug fixes.&lt;/p&gt;&lt;/li&gt; &lt;li&gt;&lt;p&gt;&lt;a href="https://github.com/tulios/kafkajs/releases/tag/v2.1.0"&gt;kafkajs 2.1&lt;/a&gt;: Kafkajs is a pure &lt;a href="https://developers.redhat.com/topics/javascript"&gt;JavaScript&lt;/a&gt; Kafka client for &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;. Users can now pause and resume consuming partitions directly from from the &lt;code&gt;eachBatch&lt;/code&gt;/&lt;code&gt;eachMessage&lt;/code&gt; handlers. This release also contains some important bug fixes.&lt;/p&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Blogs&lt;/h2&gt; &lt;p&gt;I selected some interesting blog posts and articles that were published last month:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://distributedsystemsmadeeasy.medium.com/high-watermark-distributed-design-patterns-c1f3330d8129"&gt;High watermark: Distributed design patterns&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/wise-engineering/rack-awareness-in-kafka-streams-448d7e5225a3"&gt;Rack awareness in Kafka Streams&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://medium.com/shippeo-tech-blog/debezium-to-snowflake-lessons-learned-building-data-replication-in-production-a5430a9fe85b"&gt;Debezium to Snowflake: Lessons learned building data replication in production&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To learn more about Kafka, visit &lt;a href="https://developers.redhat.com/topics/kafka-kubernetes"&gt;Red Hat Developer's Apache Kafka topic page&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/14/kafka-monthly-digest-june-2022" title="Kafka Monthly Digest: June 2022"&gt;Kafka Monthly Digest: June 2022&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mickael Maison</dc:creator><dc:date>2022-07-14T07:00:00Z</dc:date></entry><entry><title type="html">This Week in JBoss - 15 July 2022</title><link rel="alternate" href="https://www.jboss.org/posts/weekly-2022-07-14.html" /><category term="quarkus" /><category term="kubernetes" /><category term="java" /><category term="infinispan" /><category term="jakarta ee" /><category term="wildfly" /><category term="ansible" /><category term="azure app service" /><author><name>Francesco Marchioni</name><uri>https://www.jboss.org/people/francesco-marchioni</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2022-07-14.html</id><updated>2022-07-14T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="quarkus, kubernetes, java, infinispan, jakarta ee, wildfly, ansible, azure app service"&gt; &lt;h1&gt;This Week in JBoss - 15 July 2022&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Happy Friday, everyone!&lt;/p&gt; &lt;p&gt;Here is another edition of the JBoss Editorial with exciting news and updates from your JBoss communities.&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_release_roundup"&gt;Release roundup&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Here are the most recent releases for this edition:&lt;/p&gt; &lt;div class="ulist square"&gt; &lt;ul class="square"&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://quarkus.io/blog/quarkus-2-10-2-final-released/"&gt;Quarkus 2.10.2&lt;/a&gt; - There is a new maintenance release with a new round of bugfixes and documentation improvements. Besides, there is a bump version for some packages (JReleaser/Keycloak). This should be a safe upgrade upgrade for anyone already using 2.10. Check here the full &lt;a href="https://github.com/quarkusio/quarkus/releases/tag/2.10.2.Final"&gt;change log&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://github.com/kiegroup/kogito-images/releases"&gt;Kogito 1.24.0&lt;/a&gt; - We are glad to announce that the Kogito 1.24.0 release is now available!.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/download/"&gt;Camel 3.18.0&lt;/a&gt; - Apache Camel 3.18.0 it’s available. A new LTS release with 117 new features, improvements and fixes. Supports Java 11 and 17. New releases available also for the other Apache Camel Streams (Camel/K, Kamelets, Camel Kafka Connector, Camel Quarkus )&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/downloads/"&gt;WildFly 27 Alpha 2&lt;/a&gt; - A new Alpha release of WildFly 27 (Alpha 2) is available if you want a preview of Jakarta EE 10 features which will be fully available with WildFly 27&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_deploy_jboss_eap_on_microsoft_azure_red_hat_openshift"&gt;Deploy JBoss EAP on Microsoft Azure Red Hat OpenShift&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/07/06/deploy-jboss-eap-microsoft-azure-red-hat-openshift"&gt;Deploy JBoss EAP on Microsoft Azure Red Hat OpenShift&lt;/a&gt;, by Philip Hayes&lt;/p&gt; &lt;p&gt;There’s a strong demand for cloud-based JBoss EAP options from our customers. This article outlines the benefits of deploying Red Hat JBoss Enterprise Application Platform (EAP) on Red Hat OpenShift and Microsoft Azure.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_the_road_to_jboss_eap_8"&gt;The Road to JBoss EAP 8&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/articles/2022/06/24/road-jboss-eap-8"&gt;The Road to JBoss EAP 8&lt;/a&gt;, by James Falkner&lt;/p&gt; &lt;p&gt;Find out how Jakarta EE specifications have evolved since Red Hat JBoss Enterprise Application Platform 7 and what to look forward to in JBoss EAP 8.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_a_first_sip_of_jakarta_faces_4_0_on_wildfly_27"&gt;A first sip of Jakarta Faces 4.0 on WildFly 27&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="http://www.mastertheboss.com/java-ee/jsf/getting-started-with-jsf-4-0-on-wildfly-27/"&gt;Getting started with Jakarta Faces 4.0&lt;/a&gt;, by Francesco Marchioni&lt;/p&gt; &lt;p&gt;Jakarta EE 10 is almost there! Today we will have a look at what is new in Jakarta Faces 4.0 which is available in the Alpha2 version of WildFly 27.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_camel_k_operations_monitoring"&gt;Camel K Operations: Monitoring&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2022/07/camel-k-monitoring-ops/"&gt;How to monitor a Camel K Integration&lt;/a&gt;, by Pasquale Congiusti&lt;/p&gt; &lt;p&gt;How to monitor a Camel K Integration?. Fortunately, Camel-K has all it takes to let you manage this operation as smooth as possible. This article walks through it.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_youtube_video_elytron_filesystem_realm_encryption"&gt;Youtube video: Elytron Filesystem Realm Encryption&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=1K92tit2uCk"&gt;Elytron Filesystem Realm Encryption&lt;/a&gt;, by Ashpan Raskar&lt;/p&gt; &lt;p&gt;Finally, from WildFly’s youtube channel check this video by Jeff Meslin to learn how to encrypt an Elytron Filesystem Realm and how to convert old filesystem realms to newly encrypted filesystem realms.&lt;/p&gt; &lt;p&gt;&lt;em&gt;That’s all folks! Please join us again in two weeks for another round of our JBoss editorial!&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/francesco-marchioni.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Francesco Marchioni&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;</content><dc:creator>Francesco Marchioni</dc:creator></entry><entry><title>Install storage in your application cluster using Rook</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/13/install-storage-your-application-cluster-using-rook" /><author><name>Praveen Kumar</name></author><id>1438ea43-76b7-4a9b-9951-407c12bb61fc</id><updated>2022-07-13T07:00:00Z</updated><published>2022-07-13T07:00:00Z</published><summary type="html">&lt;p&gt;Developers running applications in the cloud have traditionally separated their applications from storage, but recent services such as the &lt;a href="https://github.com/rook/rook"&gt;Rook&lt;/a&gt; Operator for &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; make it easy to create storage in the cloud. This article shows how to use Rook for object storage. Our example runs a single-node &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; cluster on your laptop or desktop using &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;Red Hat OpenShift Local&lt;/a&gt; (previously known as CodeReady Containers). We'll install Rook, create object storage on OpenShift Local, and perform some &lt;a href="https://ceph.io/en/news/blog/2022/bucket-notifications-with-knative-and-rook-on-minikube2/#bucket-notifications"&gt;bucket notifications&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Rook is an open source offering from the &lt;a href="https://cncf.io"&gt;Cloud Native Computing Foundation&lt;/a&gt; (CNCF). This article creates storage using the &lt;a href="https://ceph.com/en/"&gt;Ceph&lt;/a&gt; object store.&lt;/p&gt; &lt;h2&gt;Install and run Red Hat OpenShift Local&lt;/h2&gt; &lt;p&gt;You can &lt;a href="https://developers.redhat.com/products/openshift-local/overview"&gt;download the latest release of OpenShift Local&lt;/a&gt; and follow the installation instructions to run it.&lt;/p&gt; &lt;h2&gt;Add disk space for Rook&lt;/h2&gt; &lt;p&gt;OpenShift Local doesn't provide additional disk space, so users need to create it manually and attach it to the instance. This process is specific to your operating system. The following steps work on GNU/&lt;a href="https://developers.redhat.com/topics/linux"&gt;Linux&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ qemu-img create -f raw /full/path/to/crc-extra-disk 30G $ sudo virsh attach-disk crc --source /full/path/to/crc-extra-disk --target vdb --cache none&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Log in to the OpenShift cluster&lt;/h2&gt; &lt;p&gt;Log in as the &lt;code&gt;kubeadmin&lt;/code&gt; administrative user:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ crc console --credentials $ oc login -u kubeadmin -p &lt;password&gt; https://api.crc.testing:6443 $ oc whoami kubeadmin&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Install Rook resources&lt;/h2&gt; &lt;p&gt;Rook requires custom resource definitions (CRDs), an &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operator&lt;/a&gt;, and other resources that you can install through OpenShift's &lt;code&gt;oc&lt;/code&gt; administative commmand:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/crds.yaml $ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/common.yaml $ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/operator-openshift.yaml $ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/cluster-test.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Use a secure port for the object store:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ cat &lt;&lt;EOF | oc apply -f - ################################################################################################################# # Create an object store with settings for a test environment. Only a single OSD is required in this example. # kubectl create -f object-test.yaml ################################################################################################################# apiVersion: ceph.rook.io/v1 kind: CephObjectStore metadata: name: my-store namespace: rook-ceph # namespace:cluster spec: metadataPool: replicated: size: 1 dataPool: replicated: size: 1 preservePoolsOnDelete: false gateway: service: annotations: service.beta.openshift.io/serving-cert-secret-name: my-store-tls securePort: 443 instances: 1 EOF&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Wait until all the pods in the &lt;code&gt;rook-ceph&lt;/code&gt; namespace are running. You can check that they are running through the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc get pods -n rook-ceph NAME READY STATUS RESTARTS AGE csi-cephfsplugin-provisioner-6f54f6c477-5sp9k 6/6 Running 0 29m csi-cephfsplugin-z96pz 3/3 Running 0 29m csi-rbdplugin-provisioner-6d765b47d5-pkc8j 6/6 Running 0 29m csi-rbdplugin-ssgc9 3/3 Running 0 29m rook-ceph-mgr-a-5b8f9998c6-vrglx 1/1 Running 0 27m rook-ceph-mon-a-7445f49f8-6tfjj 1/1 Running 0 27m rook-ceph-operator-5df4d596d5-sfrtw 1/1 Running 0 31m rook-ceph-osd-0-5f46f4cb58-498w6 1/1 Running 0 26m rook-ceph-osd-prepare-crc-8rwmc-master-0--1-zjcgc 0/1 Completed 0 26m rook-ceph-rgw-my-store-a-6847bcf96b-cwc9s 1/1 Running 0 17m&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Create an object bucket claim&lt;/h2&gt; &lt;p&gt;An object bucket claim (OBC) is a CRD that creates a storage class. The following commands create your OBC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/storageclass-bucket-delete.yaml $ oc apply -f https://raw.githubusercontent.com/rook/rook/master/deploy/examples/object-bucket-claim-delete.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;See the &lt;a href="https://rook.io/docs/rook/v1.8/ceph-object-bucket-claim.html"&gt;OBC configuration documentation&lt;/a&gt; for more information.&lt;/p&gt; &lt;h2&gt;Allow external access&lt;/h2&gt; &lt;p&gt;OpenShift has a route resource to expose a service externally, which you can use for the &lt;code&gt;rook-ceph-rgw-my-store&lt;/code&gt; service:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ oc create route passthrough --service=rook-ceph-rgw-my-store -n rook-ceph $ oc get route -n rook-ceph NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD rook-ceph-rgw-my-store rook-ceph-rgw-my-store-rook-ceph.apps-crc.testing rook-ceph-rgw-my-store https passthrough None&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Upload a file to your object store&lt;/h2&gt; &lt;p&gt;Amazon Web Services (AWS) provides a command-line interface (CLI) to carry out just about anything you need to do on AWS. Download the CLI if you don't already have it; you can find the Linux version &lt;a href="https://docs.aws.amazon.com/cli/v1/userguide/install-linux.html"&gt;here&lt;/a&gt;. Install it as explained in the accompanying documentation.&lt;/p&gt; &lt;p&gt;To make sure you have the AWS CLI installed, enter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ aws --version aws-cli/1.23.6 Python/3.6.8 Linux/4.18.0-348.el8.x86_64 botocore/1.25.6&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Export the required AWS variables from the cluster:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export AWS_ACCESS_KEY_ID=$(kubectl -n default get secret ceph-notification-bucket -o jsonpath='{.data.AWS_ACCESS_KEY_ID}' | base64 --decode) $ export AWS_SECRET_ACCESS_KEY=$(kubectl -n default get secret ceph-notification-bucket -o jsonpath='{.data.AWS_SECRET_ACCESS_KEY}' | base64 --decode) $ export AWS_URL=https://rook-ceph-rgw-my-store-rook-ceph.apps-crc.testing&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Get the bucket from the OBC:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ export BUCKET_NAME=$(kubectl get objectbucketclaim ceph-notification-bucket -o jsonpath='{.spec.bucketName}')&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Upload the file and ensure that it's available:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ echo "hello world" &gt; hello.txt $ aws --no-verify-ssl --endpoint-url "$AWS_URL" s3 cp hello.txt s3://"$BUCKET_NAME" upload: ./hello.txt to s3://ceph-bkt-f51b12b7-1240-48a0-b6a5-fa0a15c18e94/hello.txt $ aws --no-verify-ssl --endpoint-url "$AWS_URL" s3 ls s3://"$BUCKET_NAME" 2022-05-04 04:49:57 12 hello.txt&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Object storage is easy to install in the cloud&lt;/h2&gt; &lt;p&gt;This article has shown how to use the Rook Operator to create storage in the same cluster where your application runs. The principles can be extended to many cloud environments and types of storage.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/13/install-storage-your-application-cluster-using-rook" title="Install storage in your application cluster using Rook"&gt;Install storage in your application cluster using Rook&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Praveen Kumar</dc:creator><dc:date>2022-07-13T07:00:00Z</dc:date></entry><entry><title type="html">10 IntelliJ Idea Tips to boost your productivity</title><link rel="alternate" href="http://www.mastertheboss.com/eclipse/intellij-idea/10-intellij-idea-tips-to-boost-your-productivity/" /><author><name>F.Marchioni</name></author><id>http://www.mastertheboss.com/eclipse/intellij-idea/10-intellij-idea-tips-to-boost-your-productivity/</id><updated>2022-07-12T17:52:51Z</updated><content type="html">This article contains a collection of trips and tricks that are available in Jet Brains‘ IntelliJ Idea to take your productivity at the next level. Run anything (Ctrl + Ctrl) Run anything is an universal action that you can use to perform certain tasks much faster. Invoking it is as easy as double-pressing Ctrl. By ... The post appeared first on .</content><dc:creator>F.Marchioni</dc:creator></entry><entry><title>How to run VS Code with OpenShift Dev Spaces</title><link rel="alternate" href="https://developers.redhat.com/articles/2022/07/12/how-run-vs-code-openshift-dev-spaces" /><author><name>Mario Loriedo</name></author><id>c733c022-3094-4fe1-bba5-74d0bdffc378</id><updated>2022-07-12T07:00:00Z</updated><published>2022-07-12T07:00:00Z</published><summary type="html">&lt;p&gt;Red Hat OpenShift Dev Spaces is an &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;OpenShift&lt;/a&gt;-native developer environment server. Version 3.0 &lt;a href="https://developers.redhat.com/articles/2022/04/01/codeready-workspaces-scales-now-red-hat-openshift-dev-spaces"&gt;has just been released&lt;/a&gt;, and &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_openshift_dev_spaces/3.0/html/user_guide/selecting-an-ide#doc-wrapper"&gt;it allows you to choose the IDE that will be included in the development environment&lt;/a&gt;. Currently, the editors included with OpenShift Dev Spaces are &lt;a href="https://theia-ide.org/"&gt;Eclipse Theia&lt;/a&gt; and &lt;a href="https://www.jetbrains.com/idea/"&gt;JetBrains IntelliJ IDEA&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;What about Visual Studio Code? Although we plan to use it as the default IDE in future versions of OpenShift Dev Spaces, Visual Studio Code is not included in version 3.0. But &lt;a href="https://www.eclipse.org/che/"&gt;Eclipse Che&lt;/a&gt;, which is the upstream project for OpenShift Dev Spaces, already includes it, and we can easily use it in OpenShift Dev Spaces too. Read on to learn how this works.&lt;/p&gt; &lt;h2&gt;Select Visual Studio Code as the editor of a Dev Space environment&lt;/h2&gt; &lt;p&gt;Visual Studio Code is included in the Eclipse Che plugin registry with the identifier &lt;code&gt;che-incubator/che-code/insiders&lt;/code&gt;. OpenShift Dev Spaces has its own internal plugin registry, but it can use external registries too, including the &lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/"&gt;online Eclipse Che plugin registry&lt;/a&gt;. We can reference the online Che registry using a file in the Git repository or through a URL parameter. We'll take a quick look at each approach.&lt;/p&gt; &lt;h3&gt;Option 1: Adding che-editor.yaml in the Git repository&lt;/h3&gt; &lt;p&gt;The easiest way to use Visual Studio Code for a given project is to reference it from a &lt;code&gt;che-editor.yaml&lt;/code&gt; file in a Git repository.&lt;/p&gt; &lt;p&gt;Create a &lt;code&gt;.che&lt;/code&gt; folder and add a &lt;code&gt;che-editor.yaml&lt;/code&gt; file with the following content in it:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-json"&gt;id: che-incubator/che-code/insiders registryUrl: https://eclipse-che.github.io/che-plugin-registry/main/v3&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The first line specifies the identifier of the editor. The second line contains the URL of the plugin registry where the editor is published. We are using the online Eclipse Che plugin registry in this example.&lt;/p&gt; &lt;p&gt;Just commit and push the change to the project Git repository (Figure 1). Once the file is pushed, any OpenShift Dev Spaces remote development environment started using the Git repository URL (GitHub, GitLab and Bitbucket are supported) will use Visual Studio Code as the editor.&lt;/p&gt; &lt;figure class="align-center rhd-u-has-filter-caption" role="group"&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig1_adding-che-editor-in-git-repo.gif"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/fig1_adding-che-editor-in-git-repo.gif" width="960" height="586" alt="Adding the file .che/che-editor.yaml in a git repository" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Adding file .che/che-editor.yaml in a git repository &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;Figure 1: Adding the file .che/che-editor.yaml in a Git repository&lt;/figcaption&gt; &lt;/figure&gt; &lt;p&gt;Visual Studio Code is not the only editor that can be used from the online Che plugin registry. Here is a list of the editor IDs that can be referenced in from &lt;code&gt;.che/che-editor.yaml&lt;/code&gt;:&lt;/p&gt; &lt;div&gt; &lt;table cellspacing="0" width="686"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th scope="col"&gt;Editor&lt;/th&gt; &lt;th scope="col"&gt;Editor ID in the Che plugin registry&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;Visual Studio Code&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;che-incubator/che-code/insiders&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;JetBrains IntelliJ IDEA&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;che-incubator/che-idea/next&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;che-incubator/che-idea/latest&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt; &lt;p&gt;JetBrains PyCharm&lt;/p&gt; &lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;code&gt;che-incubator/che-pycharm/next&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;che-incubator/che-pycharm/latest&lt;/code&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;/div&gt; &lt;h3&gt;Option 2: Using the URL parameter che-editor&lt;/h3&gt; &lt;p&gt;It's not always possible to add the file &lt;code&gt;.che/che-editor.yaml&lt;/code&gt; into a Git repository. In these cases, it's still possible to specify the editor using the &lt;code&gt;che-editor&lt;/code&gt; URL parameter:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-http"&gt;https://&lt;devspaces-hostname&gt;#&lt;git-repository-url&gt;?che-editor=&lt;editor-definition-url&gt;&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Here's an example of such a URL:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-http"&gt;https://devspaces.apps.mloriedo-devworkspaces.devcluster.openshift.com/#https://github.com/devfile/api?che-editor=https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-code/insiders/devfile.yaml&lt;/code&gt;&lt;/pre&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig2_using-che-editor-url-param.gif"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/fig2_using-che-editor-url-param.gif" width="960" height="586" alt="Using the che-editor URL parameter" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Using the che-editor URL parameter &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Here is a list of available editors definitions in the Che plugin registry that can be used in the &lt;code&gt;che-editor&lt;/code&gt; URL parameter:&lt;/p&gt; &lt;table border="1" cellpadding="1" cellspacing="1" width="623"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th scope="col"&gt;Editor&lt;/th&gt; &lt;th scope="col"&gt;Link to the Che Plugin Registry definition&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;Visual Studio Code&lt;/td&gt; &lt;td&gt;&lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-code/insiders/devfile.yaml" target="_blank"&gt;devfile.yaml&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;JetBrains IntelliJ IDEA&lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-idea/latest/devfile.yaml"&gt;devfile.yaml (latest version)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-idea/next/devfile.yaml"&gt;devfile.yaml (next most recent version)&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;JetBrains PyCharm&lt;/td&gt; &lt;td&gt; &lt;p&gt;&lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-pycharm/latest/devfile.yaml"&gt;devfile.yaml (latest version)&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a href="https://eclipse-che.github.io/che-plugin-registry/main/v3/plugins/che-incubator/che-pycharm/next/devfile.yaml"&gt;devfile.yaml (next most recent version)&lt;/a&gt;&lt;/p&gt; &lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;What Visual Studio Code extensions are available?&lt;/h2&gt; &lt;p&gt;The Visual Studio Code binary that is included in the Che plugin registry is pre-configured to use the online &lt;a href="https://openvsx.org"&gt;Open VSX Registry&lt;/a&gt;, which contains thousands of extensions and is owned by the Eclipse Foundation. Those extensions can be installed from Visual Studio Code itself as usual (Figure 3).&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig3_openvsx-vs-code-extensions.gif"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/fig3_openvsx-vs-code-extensions.gif" width="960" height="586" alt="Browsing and installing Visual Studio Code extensions from Open VSX" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Browsing and installing Visual Studio Code extensions from Open VSX &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;Using Open VSX extensions in air gapped scenarios is currently not supported. We are working on an offline version of Open VSX Registry that can be used with OpenShift Dev Spaces to support such environments, but that won't be available before OpenShift Dev Spaces 3.3.&lt;/p&gt; &lt;h2&gt;Is Visual Studio Code supported for OpenShift Dev Spaces?&lt;/h2&gt; &lt;p&gt;Visual Studio Code is currently only a community project and, as such, it is not included in OpenShift Dev Spaces customer support. (The rest of your OpenShift Dev Spaces environment is fully supported; only the changed editor would not be fully supported if you installed it.) For this change, Red Hat will offer "commercially reasonable" support, which means we will try to help you but cannot make the same guarantees (with SLAs) that we make for the rest of OpenShift Dev Spaces.&lt;/p&gt; &lt;h2&gt;What's the difference between this editor and Microsoft Visual Studio Code?&lt;/h2&gt; &lt;p&gt;The Visual Studio Code-based editor used by Eclipse Che, called &lt;a href="https://github.com/che-incubator/che-code"&gt;che-code&lt;/a&gt;, is a customization of &lt;a href="https://github.com/Microsoft/vscode"&gt;Visual Studio Code Open Source&lt;/a&gt; (Code OSS). It's not a fork of Code OSS (the source code is included as a &lt;a href="https://git-scm.com/book/en/v2/Git-Tools-Advanced-Merging#_subtree_merge"&gt;Git subtree&lt;/a&gt;) and that makes it easy to automatically fetch the latest changes from Code OSS multiple times a day (currently every four hours).&lt;/p&gt; &lt;p&gt;The &lt;code&gt;che-code&lt;/code&gt; customizations include:&lt;/p&gt; &lt;ul&gt; &lt;li aria-level="1"&gt;Eclipse Che icons and labels (branding)&lt;/li&gt; &lt;li aria-level="1"&gt;A few extra built-in extensions (resource monitoring, port plugin, devfile commands, projects, and remote terminal support)&lt;/li&gt; &lt;li aria-level="1"&gt;The configuration to use the online Open VSX Registry&lt;/li&gt; &lt;li aria-level="1"&gt;An opt out from Microsoft telemetry&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Microsoft Visual Studio Code is built on top of Code OSS as well, but includes some closed source built-in extensions, uses the Microsoft Visual Studio Code extensions marketplace, and has telemetry turned on.&lt;/p&gt; &lt;p&gt;We considered using an existing project like &lt;a href="https://github.com/coder/code-server"&gt;coder&lt;/a&gt; or &lt;a href="https://github.com/gitpod-io/openvscode-server"&gt;openvscode-server&lt;/a&gt; to run Visual Studio Code in the browser. But those are forks (making them harder to rebase), and the code to run Visual Studio Code in the browser is, as of now, open source and available in Code OSS, so we don't think there is currently any value to using an intermediate project.&lt;/p&gt; &lt;h2&gt;What's the roadmap for including Visual Studio Code in OpenShift Dev Spaces?&lt;/h2&gt; &lt;p&gt;The default OpenShift Dev Spaces editor is still Eclipse Theia, but the number of Visual Studio Code extensions that can be run properly by Theia is limited. That has been our main issue for the last three years. Developers don't care much about the question of Visual Studio Code vs. Eclipse Theia, but they want to run the myriad of extensions that are available out there.&lt;/p&gt; &lt;p&gt;Our main goal for 2022 Q3 is to include a &lt;a href="https://github.com/Microsoft/vscode"&gt;Code OSS&lt;/a&gt;-based editor using Open VSX Registry in OpenShift Dev Spaces and make it the default editor. To do that, we are currently closing the feature gap with Theia. In particular, we are working on an idling mechanism to stop environments that have been inactive for a given amount of time, as well as working on support for air gapped environments.&lt;/p&gt; &lt;h2&gt;Is it possible to use Visual Studio Code on the Developer Sandbox?&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Red Hat Developer Sandbox&lt;/a&gt; hasn't been updated to OpenShift Dev Spaces yet, and it's not possible to use CodeReady Workspaces 2.15 to provision Visual Studio Code-based development environments. But the DevWorkspace Operator, the new dev environments engine used by OpenShift Dev Spaces, is installed on the Developer Sandbox (because the Web Terminal depends on it), and it supports running a Visual Studio Code-based development environment.&lt;/p&gt; &lt;p&gt;Here are some command line instructions to do that from the OpenShift Web Terminal. You can see the results in Figure 4.&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;VSCODE_SAMPLE_DW="https://eclipse-che.github.io/che-devfile-registry/main/devfiles/nodejs/devworkspace-che-code-insiders.yaml" curl -sSL "${VSCODE_SAMPLE_DW}" | sed 's/^[[:space:]]\{8,\}container:/ container:^ env: [{name: CODE_HOST, value: "0.0.0.0"}]/g' | # &lt;-- CHE IS NOT THERE sed 's/template:/template:^ attributes:^ controller.devfile.io\/storage-type: ephemeral/g' | # &lt;-- EPHEMERAL IS FASTER sed 's/volume: {}/volume: {ephemeral: true}/g' | sed '/tkn=eclipse-che/d' | tr '^' '\n' | \ oc apply -f - oc get dw nodejs-web-app --watch &lt;/code&gt;&lt;/pre&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="align-center media media--type-image media--view-mode-article-content"&gt; &lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/fig4_running-vscode-in-developer-sandbox.gif"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/fig4_running-vscode-in-developer-sandbox.gif" width="960" height="586" alt="Running Visual Studio Code in the Red Hat Developer Sandbox using the DevWorkspace Operator" loading="lazy" typeof="Image" /&gt; &lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Running Visual Studio Code in the Red Hat Developer Sandbox using the DevWorkspace Operator &lt;/div&gt; &lt;/div&gt; &lt;/article&gt; &lt;/div&gt; &lt;p&gt;We're still working on expanding editor support in OpenShift Dev Spaces. But by following the steps outlined here, users can take advantage of their familiarity with Visual Studio Code and its ecosystem of extensions today.&lt;/p&gt; &lt;p&gt;A special thank you to Rick Wagner and Florent Benoit for their review and suggestions for this article.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2022/07/12/how-run-vs-code-openshift-dev-spaces" title="How to run VS Code with OpenShift Dev Spaces"&gt;How to run VS Code with OpenShift Dev Spaces&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;</summary><dc:creator>Mario Loriedo</dc:creator><dc:date>2022-07-12T07:00:00Z</dc:date></entry></feed>
